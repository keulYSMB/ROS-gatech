#!/usr/bin/python
"""
This program is demonstration for face and object detection using haar-like features.
The program finds faces in a camera image or video stream and displays a red box around them.

Original C implementation by:  ?
Python implementation by: Roman Stanchak, James Bowman
"""
import roslib
roslib.load_manifest('opencv_tests')

import sys
import os
from optparse import OptionParser

import rospy
import sensor_msgs.msg
from array import *
from sensor_msgs.msg import RegionOfInterest
from face_detection.msg import ROIArray
from cv_bridge import CvBridge
import cv
import cv2.cv

#ROIArray = []
#publishpoint2 = ROIArray()

# Parameters for haar detection
# From the API:
# The default parameters (scale_factor=2, min_neighbors=3, flags=0) are tuned 
# for accurate yet slow object detection. For a faster operation on real video 
# images the settings are: 
# scale_factor=1.2, min_neighbors=2, flags=CV_HAAR_DO_CANNY_PRUNING, 
# min_size=<minimum possible face size

min_size = (10, 10)
image_scale = 2
haar_scale = 1.2
min_neighbors = 2
haar_flags = 0

if __name__ == '__main__':
    # pkgdir = roslib.packages.get_pkg_dir("opencv2")
    haarfile = "/opt/ros/fuerte/share/OpenCV/haarcascades/haarcascade_frontalface_alt.xml"

    parser = OptionParser(usage = "usage: %prog [options] [filename|camera_index]")
    parser.add_option("-c", "--cascade", action="store", dest="cascade", type="str", help="Haar cascade file, default %default", default = haarfile)
    (options, args) = parser.parse_args()
    
    cascade = cv.Load(options.cascade)
    br = CvBridge()
    #pub = rospy.Publisher("faceimage", ROIArray)
    pub = rospy.Publisher("faceimage", sensor_msgs.msg.RegionOfInterest)
    pub_faces = rospy.Publisher("Faces", ROIArray)


    def detect_and_draw(imgmsg):
	img = br.imgmsg_to_cv(imgmsg, "bgr8")
	imgface = br.imgmsg_to_cv(imgmsg, "bgr8")

        # allocate temporary images
	ourImage = [] #array(br.imgmsg_to_cv(imgmsg, "bgr8"))
#        ourImage2 =  br.imgmsg_to_cv(imgmsg, "bgr8")

	gray = cv.CreateImage((img.width,img.height), 8, 1)
        small_img = cv.CreateImage((cv.Round(img.width / image_scale),
                       cv.Round (img.height / image_scale)), 8, 1)

        # convert color input image to grayscale
        cv.CvtColor(img, gray, cv.CV_BGR2GRAY)

        # scale input image for faster processing
        cv.Resize(gray, small_img, cv.CV_INTER_LINEAR)

        cv.EqualizeHist(small_img, small_img)

        if(cascade):
            faces = cv.HaarDetectObjects(small_img, cascade, cv.CreateMemStorage(0),
                                         haar_scale, min_neighbors, haar_flags, min_size)
	    
            if faces:
		i=0
		images =[]
                for ((x, y, w, h), n) in faces:
		    i=i+1
                    # the input to cv.HaarDetectObjects was resized, so scale the 
                    # bounding box of each face and convert it to two CvPoints
                    pt1 = (int(x * image_scale), int(y * image_scale))
                    pt2 = (int((x + w) * image_scale), int((y + h) * image_scale))
                    cv.ShowImage("Face"+str(i),img[pt1[1]:pt2[1], pt1[0]:pt2[0]])
		    cv.Rectangle(img, pt1, pt2, cv.RGB(255, 0, 0), 3, 8, 0)
		    images.append(br.cv_to_imgmsg(img[pt1[1]:pt2[1], pt1[0]:pt2[0]], encoding="passthrough"))
		    publishpoint1 = RegionOfInterest(int(pt1[0]),int(pt1[1]),int(pt2[1]-pt1[1]),int(pt2[0]-pt1[0]),False)
		pub_faces.publish(images)  
		 #   publishpoint2 = ROIArray();
		 #   publishpoint2[n]=RegionOfInterest(int(pt1[0]),int(pt1[1]),int(pt2[1]-pt1[1]),int(pt2[0]-pt1[0]),False)
		    #ROIArray.append(publishpoint1)
		    #print(len(ROIArray))  
		 #   pub.publish(publishpoint2)
		 #   print "n = " + str(n)
		 #   for i in range(n):
		#	ourImage[i]=br.imgmsg_to_cv(imgmsg, "bgr8")
		#	ourImage[i]=cv.GetSubRect(img,(int(pt1[0]),int(pt1[1]),int(pt2[1]-pt1[1]),int(pt2[0]-pt1[0])))
		#	cv.ShowImage("resultface1", ourImage[i])
	#	    if n==1:
	#		ourImage1=cv.GetSubRect(img,(int(pt1[0]),int(pt1[1]),int(pt2[1]-pt1[1]),int(pt2[0]-pt1[0])))
	#		cv.ShowImage("resultface1", ourImage1)
	#	    elif n==2:
	#		ourImage2=cv.GetSubRect(img,(int(pt1[0]),int(pt1[1]),int(pt2[1]-pt1[1]),int(pt2[0]-pt1[0])))
	#		cv.ShowImage("resultface2", ourImage2)
# pub.publish(ROIArray[i])
		   


        cv.ShowImage("result", img)
	
        cv.WaitKey(6)

    rospy.init_node('rosfacedetect')
    image_topic = rospy.resolve_name("imagename")
    rospy.Subscriber("/vrep/visionSensor", sensor_msgs.msg.Image, detect_and_draw)
    rospy.spin()
